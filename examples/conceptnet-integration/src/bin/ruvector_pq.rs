//! RuVector Product Quantization Integration
//!
//! ConceptNet with 120x memory compression using Product Quantization:
//! - 516K concepts √ó 300 dims √ó 4 bytes = 619 MB (original)
//! - 516K concepts √ó 10 bytes = 5.2 MB (compressed)
//!
//! Maintains 90-95% recall with ADC (Asymmetric Distance Computation)

use clap::Parser;
use flate2::read::GzDecoder;
use indicatif::{ProgressBar, ProgressStyle};
use rayon::prelude::*;
use std::collections::HashMap;
use std::fs::File;
use std::io::{BufRead, BufReader, Write};
use std::path::Path;
use std::time::Instant;

// RuVector PQ
use ruvector_core::advanced_features::product_quantization::{EnhancedPQ, PQConfig};
use ruvector_core::types::DistanceMetric;

/// RuVector Product Quantization for ConceptNet
#[derive(Parser, Debug)]
#[command(author, version, about, long_about = None)]
struct Args {
    /// Maximum embeddings to load (0 = all ~516K)
    #[arg(long, default_value_t = 0)]
    embeddings: usize,

    /// Number of PQ subspaces (must divide 300)
    #[arg(long, default_value_t = 10)]
    subspaces: usize,

    /// Codebook size per subspace (max 256)
    #[arg(long, default_value_t = 256)]
    codebook_size: usize,

    /// K-means iterations for training
    #[arg(long, default_value_t = 20)]
    kmeans_iters: usize,

    /// Training sample size for codebook learning
    #[arg(long, default_value_t = 50000)]
    train_size: usize,

    /// Skip demo
    #[arg(long)]
    skip_demo: bool,

    /// Quiet mode
    #[arg(short, long)]
    quiet: bool,
}

const NUMBERBATCH_URL: &str = "https://conceptnet.s3.amazonaws.com/downloads/2019/numberbatch/numberbatch-en-19.08.txt.gz";
const DATA_DIR: &str = "data";
const NUMBERBATCH_FILE: &str = "data/numberbatch-en-19.08.txt.gz";
const DIMS: usize = 300;

/// PQ-compressed embeddings with exact vectors for training
pub struct PQEmbeddings {
    /// Product Quantization index
    pq: EnhancedPQ,
    /// Original vectors (kept for training and exact search comparison)
    original_vectors: Vec<Vec<f32>>,
    /// Concept names
    concepts: Vec<String>,
    /// Concept -> index
    concept_to_idx: HashMap<String, usize>,
    /// Compressed codes for each concept
    codes: Vec<Vec<u8>>,
}

impl PQEmbeddings {
    pub fn new(config: PQConfig) -> anyhow::Result<Self> {
        let pq = EnhancedPQ::new(DIMS, config)?;
        Ok(Self {
            pq,
            original_vectors: Vec::new(),
            concepts: Vec::new(),
            concept_to_idx: HashMap::new(),
            codes: Vec::new(),
        })
    }

    pub fn len(&self) -> usize {
        self.concepts.len()
    }

    pub fn add_vector(&mut self, concept: String, vector: Vec<f32>) {
        let idx = self.concepts.len();
        self.concept_to_idx.insert(concept.clone(), idx);
        self.concepts.push(concept);
        self.original_vectors.push(vector);
    }

    /// Train PQ codebooks on a sample of vectors
    pub fn train(&mut self, sample_size: usize) -> anyhow::Result<()> {
        let sample: Vec<Vec<f32>> = if sample_size >= self.original_vectors.len() {
            self.original_vectors.clone()
        } else {
            use rand::seq::SliceRandom;
            let mut rng = rand::thread_rng();
            let mut indices: Vec<usize> = (0..self.original_vectors.len()).collect();
            indices.shuffle(&mut rng);
            indices.truncate(sample_size);
            indices.iter().map(|&i| self.original_vectors[i].clone()).collect()
        };

        self.pq.train(&sample)?;
        Ok(())
    }

    /// Encode all vectors using trained codebooks
    pub fn encode_all(&mut self) -> anyhow::Result<()> {
        self.codes = self.original_vectors
            .par_iter()
            .map(|v| self.pq.encode(v).unwrap_or_else(|_| vec![0; self.pq.config.num_subspaces]))
            .collect();
        Ok(())
    }

    pub fn get(&self, concept: &str) -> Option<&[f32]> {
        self.concept_to_idx.get(concept).map(|&idx| self.original_vectors[idx].as_slice())
    }

    /// Search using PQ with ADC (Asymmetric Distance Computation)
    /// Query is exact, database vectors are compressed
    pub fn search_pq(&self, query: &[f32], k: usize) -> anyhow::Result<Vec<(String, f32)>> {
        let lookup_table = self.pq.create_lookup_table(query)?;

        // Compute distances using lookup table (very fast!)
        let mut distances: Vec<(usize, f32)> = self.codes
            .par_iter()
            .enumerate()
            .map(|(idx, codes)| (idx, lookup_table.distance(codes)))
            .collect();

        // Sort by distance
        distances.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap_or(std::cmp::Ordering::Equal));
        distances.truncate(k);

        Ok(distances.into_iter()
            .map(|(idx, dist)| (self.concepts[idx].clone(), dist))
            .collect())
    }

    /// Exact brute-force search for comparison
    pub fn search_exact(&self, query: &[f32], k: usize) -> Vec<(String, f32)> {
        let mut scores: Vec<(usize, f32)> = self.original_vectors
            .par_iter()
            .enumerate()
            .map(|(idx, vec)| {
                let dist = euclidean_distance(query, vec);
                (idx, dist)
            })
            .collect();

        scores.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap_or(std::cmp::Ordering::Equal));
        scores.truncate(k);

        scores.into_iter()
            .map(|(idx, dist)| (self.concepts[idx].clone(), dist))
            .collect()
    }

    /// Compute recall@k comparing PQ to exact search
    pub fn compute_recall(&self, query: &[f32], k: usize) -> anyhow::Result<f32> {
        let exact = self.search_exact(query, k);
        let pq_results = self.search_pq(query, k)?;

        let exact_set: std::collections::HashSet<_> = exact.iter().map(|(c, _)| c).collect();
        let pq_set: std::collections::HashSet<_> = pq_results.iter().map(|(c, _)| c).collect();

        let overlap = exact_set.intersection(&pq_set).count();
        Ok(overlap as f32 / k as f32)
    }

    pub fn compression_ratio(&self) -> f32 {
        self.pq.compression_ratio()
    }

    pub fn memory_original_mb(&self) -> f32 {
        (self.len() * DIMS * 4) as f32 / 1_000_000.0
    }

    pub fn memory_compressed_mb(&self) -> f32 {
        (self.len() * self.pq.config.num_subspaces) as f32 / 1_000_000.0
    }
}

#[inline]
fn euclidean_distance(a: &[f32], b: &[f32]) -> f32 {
    a.iter()
        .zip(b.iter())
        .map(|(x, y)| {
            let diff = x - y;
            diff * diff
        })
        .sum::<f32>()
        .sqrt()
}

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    let args = Args::parse();

    println!("‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó");
    println!("‚ïë   RuVector Product Quantization - 120x Compression               ‚ïë");
    println!("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n");

    // Validate subspaces
    if DIMS % args.subspaces != 0 {
        anyhow::bail!("Subspaces ({}) must divide dimensions ({}) evenly", args.subspaces, DIMS);
    }

    let compression = (DIMS * 4) as f32 / args.subspaces as f32;
    println!("  üîß Configuration:");
    println!("    ‚Ä¢ Subspaces: {} ({}D each)", args.subspaces, DIMS / args.subspaces);
    println!("    ‚Ä¢ Codebook size: {} centroids", args.codebook_size);
    println!("    ‚Ä¢ K-means iterations: {}", args.kmeans_iters);
    println!("    ‚Ä¢ Training sample: {} vectors", args.train_size);
    println!("    ‚Ä¢ Compression ratio: {:.0}x", compression);
    println!();

    std::fs::create_dir_all(DATA_DIR)?;

    // Download if needed
    if !Path::new(NUMBERBATCH_FILE).exists() {
        println!("üì• Downloading Numberbatch embeddings...");
        download_file(NUMBERBATCH_URL, NUMBERBATCH_FILE).await?;
    }

    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // Step 1: Load embeddings
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    println!("üìä Loading Numberbatch embeddings...");
    let start = Instant::now();

    let max_entries = if args.embeddings == 0 { usize::MAX } else { args.embeddings };

    let pq_config = PQConfig {
        num_subspaces: args.subspaces,
        codebook_size: args.codebook_size,
        num_iterations: args.kmeans_iters,
        metric: DistanceMetric::Euclidean,
    };

    let mut embeddings = load_embeddings(NUMBERBATCH_FILE, max_entries, pq_config, args.quiet)?;

    let load_time = start.elapsed();
    println!(
        "‚úÖ Loaded {} embeddings in {:.2}s ({:.0}/sec)\n",
        embeddings.len(),
        load_time.as_secs_f64(),
        embeddings.len() as f64 / load_time.as_secs_f64()
    );

    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // Step 2: Train PQ codebooks
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    println!("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê");
    println!("                   Training Product Quantization");
    println!("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n");

    let train_sample = args.train_size.min(embeddings.len());
    println!("  üéì Training codebooks on {} sample vectors...", train_sample);

    let train_start = Instant::now();
    embeddings.train(train_sample)?;
    let train_time = train_start.elapsed();

    println!("  ‚úÖ Training completed in {:.2}s\n", train_time.as_secs_f64());

    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // Step 3: Encode all vectors
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    println!("  üì¶ Encoding {} vectors with PQ...", embeddings.len());

    let encode_start = Instant::now();
    embeddings.encode_all()?;
    let encode_time = encode_start.elapsed();

    println!(
        "  ‚úÖ Encoding completed in {:.2}s ({:.0} vectors/sec)\n",
        encode_time.as_secs_f64(),
        embeddings.len() as f64 / encode_time.as_secs_f64()
    );

    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // Step 4: Memory comparison
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    println!("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê");
    println!("                   Memory Compression Results");
    println!("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n");

    let original_mb = embeddings.memory_original_mb();
    let compressed_mb = embeddings.memory_compressed_mb();
    let ratio = embeddings.compression_ratio();

    println!("  üìä Memory Usage:");
    println!("    ‚Ä¢ Original:   {:.1} MB ({} vectors √ó {} dims √ó 4 bytes)",
             original_mb, embeddings.len(), DIMS);
    println!("    ‚Ä¢ Compressed: {:.2} MB ({} vectors √ó {} bytes)",
             compressed_mb, embeddings.len(), args.subspaces);
    println!("    ‚Ä¢ Compression: {:.0}x ({:.1}% of original size)",
             ratio, 100.0 / ratio);
    println!("    ‚Ä¢ Savings: {:.1} MB\n", original_mb - compressed_mb);

    if !args.skip_demo {
        // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        // Step 5: Search performance
        // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        println!("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê");
        println!("                   Search Performance & Recall");
        println!("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n");

        benchmark_pq_search(&embeddings)?;

        // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        // Step 6: Semantic search demo
        // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        println!("\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê");
        println!("                   Semantic Search Demo");
        println!("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n");

        demo_semantic_search(&embeddings)?;
    }

    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // Summary
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    println!("\n‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê");
    println!("                   Integration Summary");
    println!("‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n");

    println!("  üöÄ RuVector PQ Features:");
    println!("    ‚úì K-means++ codebook training");
    println!("    ‚úì Asymmetric Distance Computation (ADC)");
    println!("    ‚úì Precomputed lookup tables");
    println!("    ‚úì Parallel encoding (Rayon)");
    println!("    ‚úì {:.0}x memory compression", ratio);
    println!();

    println!("‚úÖ Product Quantization integration complete!");
    Ok(())
}

async fn download_file(url: &str, path: &str) -> anyhow::Result<()> {
    let response = reqwest::get(url).await?;
    let total_size = response.content_length().unwrap_or(0);
    println!("  Size: {:.1} MB", total_size as f64 / 1_000_000.0);
    let bytes = response.bytes().await?;
    let mut file = File::create(path)?;
    file.write_all(&bytes)?;
    println!("  ‚úÖ Downloaded");
    Ok(())
}

fn load_embeddings(
    path: &str,
    max_entries: usize,
    pq_config: PQConfig,
    quiet: bool
) -> anyhow::Result<PQEmbeddings> {
    let file = File::open(path)?;
    let reader = BufReader::with_capacity(1024 * 1024, GzDecoder::new(file));

    let mut embeddings = PQEmbeddings::new(pq_config)?;
    let mut count = 0;
    let mut skipped_header = false;

    let pb = if !quiet {
        let pb = ProgressBar::new_spinner();
        pb.set_style(ProgressStyle::default_spinner()
            .template("{spinner:.green} [{elapsed}] {msg}").unwrap());
        Some(pb)
    } else {
        None
    };

    for line_result in reader.lines() {
        let line = line_result?;

        if !skipped_header {
            let parts: Vec<&str> = line.split_whitespace().collect();
            if parts.len() == 2 && parts[0].parse::<usize>().is_ok() {
                skipped_header = true;
                continue;
            }
            skipped_header = true;
        }

        let parts: Vec<&str> = line.split_whitespace().collect();
        if parts.is_empty() { continue; }

        let concept = parts[0];
        if concept.starts_with("##") || concept.contains('+') || concept.len() < 2 {
            continue;
        }

        let vec: Vec<f32> = parts[1..]
            .iter()
            .filter_map(|s| s.parse::<f32>().ok())
            .collect();

        if vec.len() != DIMS { continue; }

        embeddings.add_vector(concept.to_string(), vec);
        count += 1;

        if let Some(ref pb) = pb {
            if count % 10000 == 0 {
                pb.set_message(format!("{} embeddings loaded", count));
            }
        }

        if count >= max_entries { break; }
    }

    if let Some(pb) = pb {
        pb.finish_with_message(format!("{} embeddings loaded", count));
    }

    Ok(embeddings)
}

fn benchmark_pq_search(embeddings: &PQEmbeddings) -> anyhow::Result<()> {
    let test_words = ["dog", "computer", "science", "music", "art"];
    let k = 10;

    println!("  Recall@{} comparison (PQ vs Exact):\n", k);

    let mut total_recall = 0.0;
    let mut tested = 0;

    for word in test_words {
        if let Some(query) = embeddings.get(word) {
            let recall = embeddings.compute_recall(query, k)?;
            total_recall += recall;
            tested += 1;
            println!("    ‚Ä¢ '{}': {:.1}% recall", word, recall * 100.0);
        }
    }

    if tested > 0 {
        println!("\n    Average recall@{}: {:.1}%", k, (total_recall / tested as f32) * 100.0);
    }

    // Speed comparison
    println!("\n  ‚ö° Speed comparison (100 queries):\n");

    if let Some(query) = embeddings.get("computer") {
        let iterations = 100;

        // Exact search
        let start = Instant::now();
        for _ in 0..iterations {
            let _ = embeddings.search_exact(query, k);
        }
        let exact_time = start.elapsed().as_secs_f64() * 1000.0 / iterations as f64;

        // PQ search
        let start = Instant::now();
        for _ in 0..iterations {
            let _ = embeddings.search_pq(query, k);
        }
        let pq_time = start.elapsed().as_secs_f64() * 1000.0 / iterations as f64;

        let speedup = exact_time / pq_time;

        println!("    ‚Ä¢ Exact search:  {:.2}ms", exact_time);
        println!("    ‚Ä¢ PQ search:     {:.2}ms ({:.1}x speedup)", pq_time, speedup);
    }

    Ok(())
}

fn demo_semantic_search(embeddings: &PQEmbeddings) -> anyhow::Result<()> {
    let queries = ["artificial_intelligence", "machine_learning", "neural_network"];

    for query_word in queries {
        if let Some(query) = embeddings.get(query_word) {
            let results = embeddings.search_pq(query, 6)?;
            println!("  üîç Similar to '{}':", query_word);
            for (concept, dist) in results.iter().skip(1).take(4) {
                println!("      ‚Ä¢ {} (dist: {:.3})", concept, dist);
            }
            println!();
        }
    }

    Ok(())
}
