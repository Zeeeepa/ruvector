# Orbital Pole Clustering - Technical Specification

**Agent:** Analysis Agent 15
**Purpose:** Detect and quantify orbital pole clustering in TNO populations
**Algorithms:** Spherical vector statistics, von Mises distribution fitting
**Output Formats:** JSON, formatted text reports, statistical summaries

---

## 1. Mathematical Formulations

### 1.1 Pole Vector Conversion

**Input:** Orbital elements (Î©, i)
- Î©: Longitude of ascending node (degrees, 0-360)
- i: Inclination (degrees, 0-180)

**Conversion to Cartesian (x, y, z):**

```
Convert to radians:
  Î©_rad = Î© Ã— Ï€/180
  i_rad = i Ã— Ï€/180

Calculate components:
  x = sin(i_rad) Ã— cos(Î©_rad)
  y = sin(i_rad) Ã— sin(Î©_rad)
  z = cos(i_rad)

Normalize to unit length:
  magnitude = âˆš(xÂ² + yÂ² + zÂ²)
  x_norm = x / magnitude
  y_norm = y / magnitude
  z_norm = z / magnitude
```

**Output:** Unit pole vector **v** = [x_norm, y_norm, z_norm]

**Validity Conditions:**
- Magnitude should equal 1.0 (within floating-point precision)
- Components should satisfy: -1 â‰¤ x, y, z â‰¤ 1
- If xÂ² + yÂ² > sinÂ²(i), orbital plane is tilted

---

### 1.2 Mean Pole Vector Calculation

**Input:** Set of unit vectors {vâ‚, vâ‚‚, ..., vâ‚™}

**Vector Sum:**
```
S_x = Î£ v_i,x  (sum of x-components)
S_y = Î£ v_i,y  (sum of y-components)
S_z = Î£ v_i,z  (sum of z-components)

Vector sum magnitude:
||S|| = âˆš(S_xÂ² + S_yÂ² + S_zÂ²)
```

**Resultant Vector Length (R-value):**
```
R = ||S|| / n

Where n = number of objects
```

**Mean Pole Direction (normalized):**
```
v_mean,x = S_x / ||S||
v_mean,y = S_y / ||S||
v_mean,z = S_z / ||S||
```

**Physical Interpretation:**
- R = 0: Poles uniformly distributed (random)
- R = 1: All poles perfectly aligned
- Intermediate R: Partial clustering

---

### 1.3 Clustering Strength Assessment

**Clustering Strength = R-value** (from circular statistics)

```
Classification thresholds:
  R < 0.3:        WEAK         (confidence: 20%)
  0.3 â‰¤ R < 0.5:  MODERATE     (confidence: 50%)
  0.5 â‰¤ R < 0.7:  STRONG       (confidence: 75%)
  R â‰¥ 0.7:        VERY_STRONG  (confidence: 95%)
```

**Sample Size Correction:**

For small samples (n < 25), apply Rayleigh correction:

```
R_corrected = R Ã— (1 - (3/(8Îº)))  [for Îº large]
```

---

### 1.4 Concentration Parameter (Îº - Kappa)

The von Mises concentration parameter quantifies clustering strength.

**Three-region approximation:**

```
Region 1: R < 0.53
  Îº = 2R + 8RÂ³

Region 2: 0.53 â‰¤ R < 0.85
  Îº = 0.4 + 1.39R/(1-R)

Region 3: R â‰¥ 0.85
  Îº = ln(1/(1-R)) - 2/(1-R) + 1/(1-R)Â²
```

**Interpretation:**
- Îº = 0: Uniform distribution
- Îº = 1: Modest clustering
- Îº = 10: Strong clustering
- Îº = 100+: Extreme clustering (highly significant)

**Inverse Formula** (to recover R from Îº):

```
For Îº < 2:  R â‰ˆ âˆš(Îº/(2-Îº))
For Îº â‰¥ 2:  R â‰ˆ Îº/(4 + Îº - âˆš(4 + 8Îº))
```

---

### 1.5 Angular Distance Metric

**Input:** Two unit vectors vâ‚ and vâ‚‚

**Dot Product:**
```
cos_angle = vâ‚ Â· vâ‚‚ = vâ‚,x Ã— vâ‚‚,x + vâ‚,y Ã— vâ‚‚,y + vâ‚,z Ã— vâ‚‚,z

Clamp to valid range:
cos_angle = max(-1, min(1, cos_angle))
```

**Angular Distance (radians):**
```
Î¸ = arccos(cos_angle)
```

**Convert to Degrees:**
```
Î¸_degrees = Î¸ Ã— 180/Ï€
```

**Properties:**
- 0Â° â‰¤ Î¸ â‰¤ 180Â°
- 0Â° = perfect alignment
- 90Â° = perpendicular
- 180Â° = opposite directions

---

### 1.6 Mean Residual Angle

**Input:** Set of poles {vâ‚, ..., vâ‚™} and mean pole v_mean

**Residual Angles:**
```
For each object i:
  Î¸_i = angular_distance(v_i, v_mean)
```

**Mean Residual Angle:**
```
Î¸_mean = (Î£ Î¸_i) / n
```

**Interpretation:**
- Small Î¸_mean (e.g., 10Â°): Tight clustering
- Large Î¸_mean (e.g., 45Â°): Loose clustering
- Î¸_mean â‰ˆ 60Â°: Random (expected for uniform distribution)

---

### 1.7 Circular Mean Angle

For circular/spherical data (e.g., Î© values), must use circular mean.

**Standard Mean (WRONG for circular data):**
```
Î¸_simple = Î£ Î¸_i / n
[Problem: atan(0Â°) + tan(350Â°) â‰ˆ 175Â°, not 0Â°]
```

**Circular Mean (CORRECT):**
```
sin_sum = Î£ sin(Î¸_i [rad])
cos_sum = Î£ cos(Î¸_i [rad])

Î¸_circular = atan2(sin_sum, cos_sum)  [in radians]
Î¸_circular_deg = Î¸_circular Ã— 180/Ï€

Normalize to 0-360:
if Î¸_circular_deg < 0:
  Î¸_circular_deg += 360
```

---

## 2. Cluster Detection Algorithm

### 2.1 Distance-Based Clustering

**Method:** Simple greedy clustering using angular distance threshold

**Algorithm:**

```
INPUT: poles[] = array of pole vectors
       threshold = angular distance threshold (degrees, e.g., 30Â°)

OUTPUT: clusters[] = list of clusters

clusters = []
used = empty set

for i = 0 to poles.length:
  if i in used:
    continue

  cluster = {center: poles[i], members: [i]}
  used.add(i)

  for j = i+1 to poles.length:
    if j in used:
      continue

    distance = angular_distance(poles[i], poles[j])
    if distance < threshold:
      cluster.members.add(j)
      used.add(j)

  clusters.append(cluster)

return clusters
```

**Complexity:** O(nÂ²) for n objects

**Threshold Selection:**
- 20Â°: Fine structure, many small clusters
- 30Â°: Balance, clear families
- 45Â°: Coarse structure, few large clusters

---

### 2.2 Cluster Statistics

For each cluster:

```
cluster_count = number of members

for each member j in cluster:
  inclination_j = get_inclination(object_j)
  omega_j = get_omega(object_j)

mean_inclination = Î£ inclination_j / cluster_count
mean_omega = circular_mean([omega_j for all members])

cluster_vector_sum = Î£ v_j (for all members)
cluster_concentration = ||cluster_vector_sum|| / cluster_count
```

---

## 3. Significance Testing

### 3.1 Rayleigh Test

Tests null hypothesis: "poles are uniformly distributed"

**Test Statistic:**
```
Z = n Ã— RÂ²
```

Where n = sample size, R = clustering strength

**P-value** (for large n):
```
p = exp(-Z) Ã— (1 + (2Z - ZÂ²)/(4n) - ...)
```

**Interpretation:**
- p < 0.001: Highly significant clustering
- p < 0.05: Significant clustering
- p > 0.05: Not significant (random distribution)

**Decision Rule:**
```
if p < 0.05:
  clustering is statistically significant
else:
  cannot reject null hypothesis of random distribution
```

---

### 3.2 Bootstrap Confidence Intervals

**Method:** Resample data with replacement, recalculate R each time

```
INPUT: poles[], num_iterations = 10000

bootstrap_R = []

for k = 0 to num_iterations:
  sample = random_sample_with_replacement(poles, n=len(poles))
  R_k = calculate_clustering_strength(sample)
  bootstrap_R.append(R_k)

sort(bootstrap_R)

confidence_interval_lower = bootstrap_R[2.5th percentile]
confidence_interval_upper = bootstrap_R[97.5th percentile]

return (lower, upper)
```

---

### 3.3 Monte Carlo Test

**Method:** Generate random orbital pole distributions, compare statistics

```
INPUT: observed_poles[], num_iterations = 1000

null_statistics = []

for k = 0 to num_iterations:
  random_poles = generate_random_poles(n=len(observed_poles))
  R_null = calculate_clustering_strength(random_poles)
  null_statistics.append(R_null)

R_observed = calculate_clustering_strength(observed_poles)

p_value = (number of R_null > R_observed) / num_iterations

return p_value
```

---

## 4. Filter Parameters

### 4.1 Semi-Major Axis Filter

**Purpose:** Focus analysis on distant objects (likely Planet Nine targets)

```
INPUT: objects[], min_a = threshold (e.g., 100 AU)

OUTPUT: filtered[] = objects where a â‰¥ min_a

for obj in objects:
  if obj.a >= min_a:
    filtered.append(obj)

return filtered
```

**Common Thresholds:**
- min_a = 0: All objects (default)
- min_a = 50: Beyond classical belt
- min_a = 100: Well beyond Neptune
- min_a = 250: Extreme objects (ETNO)

---

### 4.2 Data Quality Filters

```
Valid object criteria:
  - Orbital period > 0 (well-defined orbit)
  - 0 â‰¤ e < 1 (elliptical orbit)
  - 0 â‰¤ i â‰¤ 180 (valid inclination)
  - 0 â‰¤ Î© < 360 (valid ascending node)
  - 0 â‰¤ w < 360 (valid perihelion argument)
  - a > 0 (positive semi-major axis)
  - Uncertainty in a â‰¤ 1 AU (reasonable accuracy)
```

---

## 5. Output Formats

### 5.1 JSON Report Schema

```json
{
  "analysis": "orbital_pole_clustering",
  "metadata": {
    "timestamp": "2025-11-26T00:00:00Z",
    "version": "1.0",
    "data_source": "NASA JPL SBDB"
  },
  "parameters": {
    "filter_min_a": 0.0,
    "cluster_radius_degrees": 30.0,
    "total_objects_loaded": 1234,
    "objects_analyzed": 1200
  },
  "results": {
    "total_objects": 1200,
    "clustering_objects": 1200,
    "mean_pole_vector": [0.01, 0.12, 0.99],
    "resultant_vector_length": 0.94,
    "clustering_strength": 0.9415,
    "mean_residual_angle": 16.98,
    "concentration_parameter": 260.52,
    "confidence_score": 0.95,
    "clustering_significance": "very_strong",
    "mean_inclination": 17.99,
    "mean_omega": 109.61,
    "statistical_tests": {
      "rayleigh_z": 1330.8,
      "rayleigh_p_value": 2.3e-289,
      "monte_carlo_p_value": 0.001
    }
  },
  "clusters": [
    {
      "id": 1,
      "object_count": 850,
      "center": [0.01, 0.12, 0.99],
      "mean_inclination": 15.2,
      "mean_omega": 108.5,
      "members": ["Pluto", "Eris", ...]
    }
  ],
  "interpretation": {
    "summary": "Very strong orbital pole clustering detected...",
    "confidence_level": "95%",
    "physical_interpretation": "Evidence consistent with planetary perturbation...",
    "recommendations": [...]
  }
}
```

### 5.2 Text Report Format

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  ANALYSIS AGENT 15: ORBITAL POLE CLUSTERING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š Analysis Summary:
   Total Objects Analyzed:     1200
   Objects in Clustering Set:  1200

ğŸ§­ Mean Pole Vector:
   X: 0.0112
   Y: 0.1224
   Z: 0.9924
   Magnitude: 1.0000

ğŸ“ˆ Clustering Metrics:
   Resultant Vector Length:    0.9415
   Clustering Strength (R):    0.9415
   Concentration Parameter Îº:  260.52
   Mean Residual Angle:        16.98Â°

âš¡ Significance Assessment:
   Clustering Pattern:         VERY_STRONG
   Confidence Score:           95.0%

ğŸ¯ Orbital Characteristics:
   Mean Inclination:           17.99Â°
   Mean Î© (Ascending Node):    109.61Â°

ğŸ” Statistical Tests:
   Rayleigh Test Z:            1330.80
   Rayleigh p-value:           < 0.001
   Monte Carlo p-value:        0.001

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## 6. Implementation Notes

### 6.1 Floating-Point Precision

**Considerations:**
- Use double-precision (64-bit) for accuracy
- Trigonometric functions sensitive to input precision
- Comparison of floating-point values use tolerance (e.g., 1e-10)

**Critical Operations:**
```
// Vector normalization
magnitude = sqrt(xÂ² + yÂ² + zÂ²)
if magnitude < 1e-10:
  error("zero-magnitude vector")

// Angle calculation
cos_angle = max(-1.0, min(1.0, dot_product))  // Clamp
angle = acos(cos_angle)  // Avoid numerical errors
```

---

### 6.2 Edge Cases

```
1. Empty dataset (n = 0):
   - Return all metrics as 0 or NaN
   - Significance = "undefined"

2. Single object (n = 1):
   - R = 1.0 (perfect "clustering")
   - Îº = âˆ
   - Not statistically meaningful

3. Two objects (n = 2):
   - Maximum possible R = 1.0
   - Îº potentially very large
   - Small sample correction needed

4. Collinear vectors:
   - R = 1.0, Îº = âˆ
   - Indicates perfect alignment (unlikely in real data)

5. Antipodal vectors:
   - Can cause cancellation in vector sum
   - Results in artificially low R
   - Detect and flag in output
```

---

### 6.3 Numerical Stability Issues

**Problem:** Small sample with high Îº can cause overflow in Îº calculation

**Solution:**
```
if r >= 0.9999:
  Îº = 1e6  (cap at large value)

if r <= 0.0001:
  Îº = 0    (cap at small value)
```

**Problem:** arccos() sensitive to floating-point errors

**Solution:**
```
// Instead of arccos(x) for x near Â±1:
if x > 0.9999:
  Î¸ = arccos(0.9999)
if x < -0.9999:
  Î¸ = arccos(-0.9999)
```

---

## 7. Performance Characteristics

### 7.1 Computational Complexity

| Operation | Complexity | Notes |
|-----------|-----------|-------|
| Pole conversion | O(n) | n trigonometric functions |
| Mean pole | O(n) | n vector additions |
| Clustering strength | O(n) | n dot products |
| Concentration parameter | O(1) | Closed-form formula |
| Cluster detection | O(nÂ²) | Compare all pairs |
| Angular distances | O(n) | Per reference object |

**Total:** O(nÂ²) dominated by cluster detection

### 7.2 Memory Usage

```
Array sizes:
  poles: n Ã— 3 Ã— 8 bytes = 24n bytes
  distances: n Ã— n Ã— 4 bytes = 4nÂ² bytes (for full distance matrix)

For n = 10,000:
  poles: 240 KB
  distances: 400 MB (if computed all at once)

Optimized (compute on-demand): Just 240 KB
```

### 7.3 Typical Runtime (Python)

| Dataset Size | Runtime |
|---|---|
| 100 objects | < 1 ms |
| 1,000 objects | ~10 ms |
| 10,000 objects | ~1 second |
| 100,000 objects | ~100 seconds |

---

## 8. Validation Tests

### 8.1 Unit Tests

```python
# Test 1: Known distributions
def test_perfect_alignment():
    # All poles identical
    R = calculate_clustering_strength(poles)
    assert abs(R - 1.0) < 1e-6

# Test 2: Random distribution
def test_random_poles():
    poles = [random_unit_vector() for _ in range(1000)]
    R = calculate_clustering_strength(poles)
    assert R < 0.3  # Should be very small

# Test 3: Angular distance metric
def test_angular_distance():
    v1 = [1, 0, 0]
    v2 = [0, 1, 0]
    d = angular_distance(v1, v2)
    assert abs(d - 90.0) < 1e-6  # Should be 90 degrees

# Test 4: Circular mean
def test_circular_mean():
    angles = [10, 20, 30]  # Degrees
    mean = circular_mean(angles)
    assert abs(mean - 20) < 1e-6
```

---

## 9. Future Enhancements

### 9.1 Planned Features

1. **Improved Clustering**
   - K-means clustering
   - Hierarchical clustering with dendrogram
   - DBSCAN with automatic epsilon selection

2. **Advanced Statistics**
   - Hypothesis testing for multiple clusters
   - Bayesian inference of number of clusters
   - Uncertainty propagation from orbital element errors

3. **Visualization**
   - 3D pole vector visualization (HEALPix)
   - Mollweide projection of pole distribution
   - Interactive cluster exploration

4. **Integration**
   - Direct SQL database queries
   - Streaming data support
   - API for external tools

---

**Last Updated:** 2025-11-26
**Version:** 1.0
**Status:** Production Ready
